

[[Ben L. Titzer]] ; [[2312.03858.pdf]]
https://discord.com/channels/1025104619975737446/1025104620558766166/1184811410027462707

![[Pasted image 20231214142545.png]]
--

Was only at the end there distilling my thoughts. But I suppose a way of phrasing entropy that (to me) seems more intuitive. Is saying that a lot of the information is contained within the relative structure of the information. As opposed to the probability phrasing of it with say two bits of information, to which to attribute no structural properties (or the probabilities are seen as structural properties - results of some more complicated functions or whatever). As a way of phrasing that two bits whose structure is deemed irrelevant (or probabalistically independent) is quite different from two bits connected to each-other in sequence.

---

linkedin absolutely useless for international tthings do far? ; as far as algorithms for connection/hires?