
- [ ] Same argument different perspective different conclusion. (; also as an example of a possible human confusion)

 ---
 
 The nonabsoluteness of time could also be defined as saying it is absolute in the sense of described earlier, but one would've meant by that that all perception of certain specific phenomenon are the same - those could clearly not be, but then they still change and hence you would be able to say thatm It's just that the definition of the realization of certain kinds of information isnt. It hasn't propegated yet. 

---

- [ ] Possible as an example: Rabin-Scoot theorem Jonathan tweeted which I first found (while browsing rust docs???) - Apply the inconsistency argument here, does it still make sense??

---

- universality makes assumptions of temporal stability? 
	- COmputationality/Universal computatinally equivalent in the sense that its abstraction ignores certain practicalities such as temporal factors ... but could in some way hold up in some infinite directionaly were certain assumptions to hold.
  

---

- [ ] On the sara walker simplifying complexity on time episode: It's not that "it can't happen by random chance" it's that there are two different levels of description to describe thexpoe same thing. One is without information of structures which produce the random things, the other, is "not"/less. More structure which also moght arbitrarily be coarsegrainrd, inaccurate, or with its quircks  
	- [ ] It should be: not generallt linear, but ina. particular persoective, or on a level of description it's linear. Log-ed exponential function being linear at that different level of description: coald be seen as a different corase graining, hence both not generally linear, but only if tou look at it in a particular way  

---

History: The initial side of the perceived non-trivial temporal directionality. Relying on some non-trivial consistency (; temporal invariance), in order to tell the story (; or be able to recover parts) of that initial side.  



---

// TODO: Two functions with opposite behavior which can produce their inversed results with high fidelity.  

// TODO: Inhibit the inhibition on reducing a function, if that is done and an attempt at reducing the perceivable irreducible function is made, an empty result is returned.  

---

Examples of directionalities:  
  
- [ ] General case of minimizing some directionality  
  of which temporal could be one ; applied functions/rules/.. .  
- [ ] Compressing/minimizing ambiguity  
  Priority: GIven all these ambiguities prefer definitions, or going to definitions with less confusion/less ambiguity. With the  
  added note, reasoned through 'anything can be interpreted as anything' notice the extremes, that it's not perfect. But  
  given the known descriptions, this seems least-confusing. (; could also be retrieved by sufficient differences in surrounding context)  
- [ ] Compressing/minimizing some level of description  
  Priorty: Least visual information / least complex descriptions: ((A.B).=)(C) -> A.B = C as an example. "There's no need for all this noise."  
  less redundancy in rules (distance in discoverability)  
- [ ] Exploration? - unknowns (Checking workings of functions under conditions, checking workings of functions if unknown ... fidelity ..)  
  Priority: Exploration of LHS -> RHS. (generic transformation; function exploration, lhs into rhs)  

How to phrase generalization and not these?:

Equivalence (; or partial) in input  
Equivalence in output  
Equivalence (; or partial) in sequence of steps  
Equivalence in timing      (Can timing be used in wasm? ; at some point certain memory available.)                     // ; all these given some hardware, some timing etc..  
in number of rewrite steps  
in computation complexity  
in computational effort
in intermediate representations/states
in (hardware?) axioms? 
in (optimal) interpretability (by these kind of interpreters)  
in a contextual isomorphism/symmetry (where a specific kind of asymmetry can be a certain symmetry) [ref GEB, p350 ? ]  
in ...  
(; or other symmetries)  

---

Similarly, could one say that perfect squares are similarly only possible as an abstract construction once one is bounded? THIS NEEDS BETTER UNPACKING. A CERTAIN DIRECTION/SIDE IS CONTINUED TO ITS EDGE PERFECTLY INFINITELY, until it hits some boundary.  

---

[[2023-11-10]]
Distant lights across the field at dark in the evening - through a wet glass are incredibly sensitive to my movements, or temporal movements of the planet/the processing of my mind, inducing a kind of flickering where the light came from. Perceived fast switching between states since no further structure/reducibility is in my brain to account for a larger vision field and coarsegraining is easily changed. - Something along these lines?

---

[[2023-11-15]]
Only saw Yanniks thimbnail on the most expensive cou, I'm guessing the instructions are just prompts to an llm - this is probably an example of a possibly temporally stable abstraction/cpu, though with psssible inconsistencies, can one model the inconsistencies, either account, deal, predict them

---

[[2023-11-15]]

Scaling variance: "slidescan movies scene - benjamin "

---

legal flexible definition on closness/proximity

---

[[2023-08-27]]
When one uses a concept like autonomous, its more like 'non human autonomous - the human doesn't need to', but again, not autonomous in every directionality, and the human itself also has a possible automoous directionality on it.

---

### Incoherent Examples


---

[[2023-11-27]] - Inconsistency
OK, beautiful inconsistency found here. Evidently the word "array" contains, albeit obviously "Ray" - which I hadn't realized before, - Great example of some incredibly inconsistency - just that I could abstractly make that link, doesn't necessarily mean that I am applying it everywhere, at least noticeably in my mind. - Could phrase such thing as a constructed useful but somewhat inconsistent differentiation.

---

The idea usually being that references, are connected through some arbitrary memory; RAM, disk, network, ... database. An identifier which resolved into some arbitrarily complex object.

As eluded to in https://github.com/Kindelia/HVM/blob/master/guide/HOW.md:
References are indeed the course of many problems, but they are necessary. In the same way that a lambda function `(@x(* x 2) 21)`, expresses a reference. A reference being no more than a bidirectional relationship, one which isn't necessarily reversible perfectly, but represents one all the same. For example this lambda expression: The relationship between reducing to `(* 21 2)` and re-expanding to `(@x(* x 2) 21)`. Where this re-expansion represent just one of the possible re-expansions. Sin ce reduces remove information, we wouldn't necessarily know which rule was applied. This sort of line of thinking is well-explored and relates to discussions around 'inverse' problems, the inverse through loss of information, generally considered a harder problem.

The references referred to in `HOW`, simply have more complexity than the close proximity references/structure/semantics of lambdas.

---

As a coy introduction (in Hofstadter fashion), perhaps:
> Is this pen equal to that pen? - Frowned looks -. Ok then, let me simplify the question. Is this pen equal this pen (pointing once again, at the same pen). - Frowning having increased to unprecedented levels -. Surely, a question the philosophers have answered across all human cultures and times. It's obvious, they're equal! No, you must be wrong, it's obvious they're not! Curious bystanders continuing the now precedented ritual of frowning.

---

I mentioned computer science as the branch which one could perceive from which all other sciences branch, but probably more proper would be to say that it's a reference frame: Any science as some base for primary understanding could be placed in that role as long as it has the capacity to interpret all the others to a certain extent. It just so happens that computation is a convenient language to understand. ; generalize into priors?

; Within the assumptions something like this; it's likely that any possible language / distinct scientific field, can formulate any other, or encapsulate any other possible theory as an extension of its own, or perceived 'sub-field'. The actual distinction is therefore mainly important/relevant in how it changes the observer's perspective on them. Not necessarily defining a sort of generality or 'true upper-level hierarchy' from which the fields/subfields span.

---

A note to ignore some part, is only of cognitive significance, if the imagined observer doesn't properly forget its mentioning; and why should it be ignorant to temporally relevant information? Certainly something perfectly ignorant is conceivable in this particular example, but it would certainly be unusual in some sense.

---

Allow for generation of any html/js; this would possibly allow for the system to escape the browser environment, and no guarantees are made for this dangerous proposition. (; tackle this in another way)
; a slight analogy to evolutionary biology might be made here

It boils down to the idea, that the models of computation (like Kind & HVM), are subject to arbitrarily unknown/unknowable properties of the 'hardware' they are running on. And an observer, like a human, is able to be surprised when something previously thought to be deterministic, suddenly seems not to be; or is not coherent with its model. (whether that observation is actually true or not)

But think of some property like 'commutation' being falsified in a specific context of a program, and having the runtime adjust its reductions based on such information.

Use the story of branch-prediction? Some level of description says if .. then ..., branch prediction subsides that for increased speed. Or if one uses some form of probabilities/other calculation to make the decision. --> It matters how one 'evaluates every (relevant) scenery', it can be influenced by something arbitrarily unknown.

Read: [General Intelligence Requires Rethinking Exploration (2022)](2211.07819.pdf) Aleatoric uncertainty / Epistemic uncertainty / Irreducible uncertainty ; explore these? ; or perhaps both are already captured in the vagueness of the 'conceptual uncertainty' idea.

hardware being the linux_64 or its lower level, possible reduction to tet at its hardware; sime physical process, is not accessible/reducible directly through the spec. (Indirect strategies would be required) But things could be assumed or guessed at which one can say about that underlying spec, and that it might be implemented differently and each implementation having different unknowns/ uncertainty.... etc


---

If one would note one thing from deterministic systems is that complex behavior does not need non-determinism. (? -> Response to this would be what?)

---

Open-endedness relevant ; frame of refernece/

---

Just as I don't know, nor fully udnerstand, the intricacies of my brain and other organs, just as the computer doesn't necessarily know its particular implementation in silicon, just as I presume not to know nor may not initially know how to know about a galactic nagbour.

---

More practical argument for privacy being perhaps an element of non-conformity in the sense of less connectivity to a larger network, therefore perhaps in certain cases more resilient to something like memetics. Although probably the reverse is likely relevant as well.; A quick thought as a possible conjecture on where Foundation and Earth might lead after reading its first chapter; besides the temporal differences already noted by Asimov as an argument.

---

Surely you would say the air around you is having an influence on you? And arguably a good one for I doubt your body would stay in one place without the pressure of the air.

---

(false analogy, seen in Foundation and Earth, brought this to mind:)
Notably which name is chosen/which analogy is chosen is relevant to the interpreter since things are interpreted differently. Any analogy is a 'false analogy' in some sense, it's whether the falseness/incorrectness/imperfectness of the analogy has significant consequences to the interpreter/observer. (Non-trivial/temporal/hinders the exploration of some perceived truth by another observer)

---

Machines aren't necessarily built to persist themselves through time, one could formulate this by saying they are ignorant of doing so. Arguably this is likely to change with better understanding of biology/robotics ; or more concretely physical manueverability & persistence. ; Reference to its dangers, as an example Jeff Hawkins concerns of reproducibility.

---

As a response to: 'But falsehoods device constant effort.' - What is the use of known truths if it is not for the effort required for a somewhat reliable memory? - Perhaps of some truths it can be said that their re-acquirement is of relative ease. Some, especially historical ones, in the absence of a scope which reveals previous states in the universe other than internalized memory, this is perhaps a more complex issue. Some similar argument could perhaps also be made of falsehoods. What of the lens? Is it not merely a perceived form of memory? How is it less faulty?

---

Similarly, while a human may not have direct access to the exact implementation and structures of their brain internally, something like that is more easily achieved within a computer. And similarly that also has its limitations in the form of computational boundedness and the psychical implementations (and their consistency through time). ;

---


Are you so ignorant (perhaps this is a little too harsh, but fixes the stress on this point I suppose) that perhaps understanding how the dealer shuffles the cards has not the possibility of a probabilistic edge, since it is of probabilities we speak? If you have not the guarantee of perceived fairness in the probabilities associated with the cards? Or is it merely than you cannot perceive other observers playing at the table to have devised a technique of picking up the slightest of photons as to have a probabilistic edge on the cards of others at the table?

---

After hearing the term (non-)hollonomic at Delft TU, a quick look at its definition, I reframed it as the idea that all systems are non-hollonomic (in my framework; although I didn't make this part of the assertion yesterday), except perhaps the universe itself. Or simply saying all systems are (non-)hollonomic, and ignorance makes them hollonomic, or one could make the argument that magic allows for either; Having said yesterday: "So, all dystems are non-hollonomic or magic"

---
